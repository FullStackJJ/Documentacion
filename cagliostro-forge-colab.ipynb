{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FullStackJJ/Documentacion/blob/main/cagliostro-forge-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "\n",
        "# **Cagliostro Forge Colab**\n",
        "Rise from the ashes, reborn and empowered by [lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)\n",
        "\n",
        "**Version 1.0.0** | [Github][link-to-github] | [License](https://github.com/cagliostrolab/forge-colab/blob/main/LICENSE)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=cagliostro-forge-colab&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=cagliostro-forge-colab\n",
        "[link-to-github]: https://github.com/cagliostrolab/forge-colab/blob/main/cagliostro-forge-colab.ipynb"
      ],
      "metadata": {
        "id": "GnmYPpV3o719"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# CELDA 1: LIMPIEZA Y INSTALACIÓN DE DEPENDENCIAS BÁSICAS\n",
        "# ===============================================\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Limpiar virtualenv anterior si existe\n",
        "VENV_DIR = \"/content/venv310\"\n",
        "if os.path.exists(VENV_DIR):\n",
        "    print(\"🧹 Limpiando virtualenv anterior...\")\n",
        "    shutil.rmtree(VENV_DIR)\n",
        "\n",
        "print(\"📦 Actualizando sistema...\")\n",
        "!apt-get update -y\n",
        "!apt-get install -y python3.10 python3.10-dev python3.10-venv python3.10-distutils aria2 lz4 git build-essential libssl-dev libffi-dev python3-dev\n",
        "\n",
        "print(\"📥 Descargando get-pip.py...\")\n",
        "!wget -q https://bootstrap.pypa.io/get-pip.py -O /tmp/get-pip.py\n",
        "\n",
        "print(\"✅ Dependencias básicas instaladas\")\n",
        "\n",
        "# ===============================================\n",
        "# CELDA 2: CREAR ENTORNO VIRTUAL Y INSTALAR PYTORCH\n",
        "# ===============================================\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "VENV_DIR = \"/content/venv310\"\n",
        "PYTHON = os.path.join(VENV_DIR, \"bin/python\")\n",
        "PIP_PATH = os.path.join(VENV_DIR, \"bin/pip\")\n",
        "\n",
        "print(\"🔨 Creando virtualenv Python 3.10...\")\n",
        "result = subprocess.run([\"python3.10\", \"-m\", \"venv\", VENV_DIR], capture_output=True, text=True)\n",
        "if result.returncode != 0:\n",
        "    print(f\"❌ Error creando venv: {result.stderr}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Verificar que el venv se creó correctamente\n",
        "time.sleep(1)\n",
        "if not os.path.exists(PYTHON):\n",
        "    print(f\"❌ Error: {PYTHON} no existe\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"✅ Virtualenv creado en {VENV_DIR}\")\n",
        "\n",
        "# Instalar pip, setuptools, wheel dentro del venv\n",
        "print(\"📦 Instalando pip, setuptools, wheel...\")\n",
        "result = subprocess.run([PYTHON, \"/tmp/get-pip.py\", \"--upgrade\"], capture_output=True, text=True)\n",
        "if result.returncode != 0:\n",
        "    print(f\"⚠️  Warning: {result.stderr}\")\n",
        "    # Intentar con ensurepip\n",
        "    print(\"🔄 Intentando con ensurepip...\")\n",
        "    subprocess.run([PYTHON, \"-m\", \"ensurepip\", \"--upgrade\"], check=True)\n",
        "\n",
        "# Reinstalar dependencias base usando el pip del venv\n",
        "print(\"⚙️  Configurando pip...\")\n",
        "subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"--upgrade\", \"pip\"], check=True)\n",
        "subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"setuptools\", \"wheel\"], check=True)\n",
        "\n",
        "print(\"✅ Pip, setuptools y wheel instalados\")\n",
        "\n",
        "# Instalar PyTorch ANTES que nada\n",
        "print(\"🔥 Instalando PyTorch...\")\n",
        "subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\",\n",
        "    \"torch\", \"torchvision\", \"torchaudio\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
        "], check=True)\n",
        "\n",
        "print(\"✅ PyTorch instalado\")\n",
        "\n",
        "# Instalar dependencias de colablib\n",
        "print(\"📦 Instalando dependencias de colablib...\")\n",
        "deps = [\n",
        "    \"gitpython\", \"pydantic\", \"pillow\", \"requests\", \"tqdm\",\n",
        "    \"omegaconf\", \"einops\", \"transformers>=4.25.0\", \"safetensors\",\n",
        "    \"diffusers\", \"controlnet-aux\", \"piexif\"\n",
        "]\n",
        "subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\"] + deps, check=True)\n",
        "\n",
        "print(\"✅ Dependencias instaladas\")\n",
        "\n",
        "# Instalar colablib\n",
        "print(\"🚀 Instalando colablib...\")\n",
        "subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"--upgrade\",\n",
        "    \"git+https://github.com/Linaqruf/colablib\"\n",
        "], check=True)\n",
        "\n",
        "print(\"\\n✅✅✅ ENTORNO COMPLETAMENTE CONFIGURADO ✅✅✅\\n\")\n",
        "\n",
        "# ===============================================\n",
        "# CELDA 3: CÓDIGO PRINCIPAL COMPLETO\n",
        "# ===============================================\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# FORZAR USO DE PYTHON 3.10\n",
        "VENV_DIR = \"/content/venv310\"\n",
        "PYTHON = os.path.join(VENV_DIR, \"bin/python\")\n",
        "PIP_PATH = os.path.join(VENV_DIR, \"bin/pip\")\n",
        "\n",
        "# Verificar que el venv existe y es correcto\n",
        "import subprocess as sp\n",
        "result = sp.run([PYTHON, \"--version\"], capture_output=True, text=True)\n",
        "print(f\"🔍 Python detectado en venv: {result.stdout.strip()}\")\n",
        "\n",
        "# Forzar que THIS script use Python 3.10 también (para imports)\n",
        "if \"3.10\" not in result.stdout:\n",
        "    print(\"⚠️  ADVERTENCIA: El venv no es Python 3.10!\")\n",
        "    print(\"Continuando de todas formas...\")\n",
        "\n",
        "python_version = \"3.10\"\n",
        "python_path = Path(f\"/content/venv310/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "# Limpiar sys.path y agregar SOLO el venv\n",
        "sys.path = [str(python_path)] + [p for p in sys.path if \"venv310\" not in p]\n",
        "\n",
        "# Importar librerías necesarias\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils import py_utils, package_utils, config_utils\n",
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "from colablib.utils.git_utils import update_repo, reset_repo, validate_repo, batch_update\n",
        "from colablib.utils.py_utils import get_filename\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "class CustomDirs(BaseModel):\n",
        "    url: str\n",
        "    dst: str\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive          = False  # @param {type: 'boolean'}\n",
        "output_drive_folder  = \"cagliostro-colab-forge\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Repo Config**\n",
        "update_webui         = True  # @param {type: 'boolean'}\n",
        "update_extensions    = False  # @param {type: 'boolean'}\n",
        "commit_hash          = \"\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Download Config**\n",
        "# @markdown > Check only the options you need\n",
        "animagine_xl_3_1     = True  # @param {type: 'boolean'}\n",
        "rae_diffusion_xl_v2  = False  # @param {type: 'boolean'}\n",
        "kivotos_xl_v2_0      = True  # @param {type: 'boolean'}\n",
        "urangdiffusion_2_0   = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown > **Note:**\n",
        "# @markdown - For multiple URLs, use comma separation (e.g. `url1, url2, url3`)\n",
        "# @markdown - Forge supports FLUX, SD, and SDXL, but this notebook focuses only on SDXL\n",
        "# @markdown - **Highly Recommended:** Use Hugging Face links whenever possible\n",
        "custom_model_url     = \"\"  # @param {'type': 'string'}\n",
        "custom_vae_url       = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl.vae.safetensors\"  # @param {'type': 'string'}\n",
        "custom_lora_url      = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "# @markdown ### **Tunnel Config**\n",
        "# @markdown > Default to `--share` until `ngrok_token` is not `None`\n",
        "ngrok_token          = \"\"  # @param {type: 'string'}\n",
        "ngrok_region         = \"ap\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "# @markdown ### **UI/UX Config**\n",
        "gradio_theme         = \"remilia/Ghostly\"  # @param [\"Default\", \"gradio/base\", \"gradio/glass\", \"gradio/monochrome\", \"gradio/seafoam\", \"gradio/soft\", \"gradio/dracula_test\", \"abidlabs/dracula_test\", \"abidlabs/Lime\", \"abidlabs/pakistan\", \"Ama434/neutral-barlow\", \"dawood/microsoft_windows\", \"finlaymacklon/smooth_slate\", \"Franklisi/darkmode\", \"freddyaboulton/dracula_revamped\", \"freddyaboulton/test-blue\", \"gstaff/xkcd\", \"Insuz/Mocha\", \"Insuz/SimpleIndigo\", \"JohnSmith9982/small_and_pretty\", \"nota-ai/theme\", \"nuttea/Softblue\", \"ParityError/Anime\", \"reilnuud/polite\", \"remilia/Ghostly\", \"rottenlittlecreature/Moon_Goblin\", \"step-3-profit/Midnight-Deep\", \"Taithrah/Minimal\", \"ysharma/huggingface\", \"ysharma/steampunk\", \"NoCrypt/miku\"]\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets          = True  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Launch Arguments**\n",
        "use_gradio_auth      = False  # @param {type: 'boolean'}\n",
        "auto_select_model    = False  # @param {type: 'boolean'}\n",
        "auto_select_vae      = True  # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --theme dark --no-half-vae --opt-sdp-attention\"  # @param {type: 'string'}\n",
        "\n",
        "################################\n",
        "# GLOBAL VARIABLES GOES HERE\n",
        "################################\n",
        "\n",
        "# GRADIO AUTH\n",
        "user      = \"cagliostro\"\n",
        "password  = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir        = Path(\"/content\")\n",
        "drive_dir       = root_dir / \"drive\" / \"MyDrive\"\n",
        "repo_dir        = root_dir / \"stable-diffusion-webui-forge\"\n",
        "tmp_dir         = root_dir / \"tmp\"\n",
        "\n",
        "models_dir      = repo_dir / \"models\"\n",
        "extensions_dir  = repo_dir / \"extensions\"\n",
        "ckpt_dir        = models_dir / \"Stable-diffusion\"\n",
        "vae_dir         = models_dir / \"VAE\"\n",
        "lora_dir        = models_dir / \"Lora\"\n",
        "output_subdir   = [\"txt2img-samples\", \"img2img-samples\", \"extras-samples\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "config_file_path    = repo_dir / \"config.json\"\n",
        "ui_config_file_path = repo_dir / \"ui-config.json\"\n",
        "\n",
        "package_url = [\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge-deps.tar.lz4\",\n",
        "]\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\" : CustomDirs(url=custom_model_url, dst=str(ckpt_dir)),\n",
        "    \"vae\"   : CustomDirs(url=custom_vae_url, dst=str(vae_dir)),\n",
        "    \"lora\"  : CustomDirs(url=custom_lora_url, dst=str(lora_dir)),\n",
        "}\n",
        "\n",
        "default_model_urls = {\n",
        "    \"animagine_xl_3_1\"      : \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\",\n",
        "    \"rae_diffusion_xl_v2\"   : \"https://huggingface.co/Raelina/Rae-Diffusion-XL-V2/resolve/main/RaeDiffusion-XL-v2.safetensors\",\n",
        "    \"kivotos_xl_v2_0\"       : \"https://huggingface.co/yodayo-ai/kivotos-xl-2.0/resolve/main/kivotos-xl-2.0.safetensors\",\n",
        "    \"urangdiffusion_2_0\"    : \"https://huggingface.co/kayfahaarukku/UrangDiffusion-2.0/resolve/main/UrangDiffusion-2.0.safetensors\",\n",
        "}\n",
        "\n",
        "################################\n",
        "# HELPER FUNCTIONS STARTS HERE\n",
        "################################\n",
        "\n",
        "def mount_drive_function(directory):\n",
        "    output_dir = repo_dir / \"outputs\"\n",
        "\n",
        "    if mount_drive:\n",
        "        print_line(80, color=\"green\")\n",
        "        if not directory.exists():\n",
        "            from google.colab import drive\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(str(directory.parent))\n",
        "        output_dir = directory / output_drive_folder\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [ckpt_dir, vae_dir, lora_dir]:\n",
        "        dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    ffmpy_path = python_path / \"ffmpy-0.3.0.dist-info\"\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename = Path(url).name\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == \"webui-forge-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, str(python_path), overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(dir / filename)\n",
        "\n",
        "    if ffmpy_path.exists():\n",
        "        subprocess.run([\"rm\", \"-rf\", str(ffmpy_path)])\n",
        "    subprocess.run([PYTHON, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"ffmpy\"], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps = [\"aria2\", \"lz4\"]\n",
        "    cprint(\"Installing ubuntu dependencies\", color=\"green\")\n",
        "    subprocess.run([\"apt\", \"install\", \"-y\"] + ubuntu_deps, check=True)\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    if not repo_dir.exists():\n",
        "        pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "    else:\n",
        "        cprint(\"Stable Diffusion Web UI Forge already installed, skipping...\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    try:\n",
        "        config = config_utils.read_config(str(config_path))\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        config = {}\n",
        "\n",
        "    config_updates = {\n",
        "        f\"outdir_{subdir.split('-')[0]}_{'_'.join(subdir.split('-')[1:])}\": str(output_dir / subdir)\n",
        "        for subdir in output_subdir\n",
        "    }\n",
        "    config.update(config_updates)\n",
        "\n",
        "    config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    config_utils.write_config(str(config_path), config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        (output_dir / dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(\"Preparing environment...\", color=\"green\")\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF']   = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]      = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]            = \"ignore\"\n",
        "\n",
        "def custom_download(custom_dirs):\n",
        "    filtered_urls = filter_dict_items(default_model_urls)\n",
        "\n",
        "    for key, value in custom_dirs.items():\n",
        "        urls = value.url.split(\",\") if value.url else []\n",
        "        dst = value.dst\n",
        "\n",
        "        if key == \"model\":\n",
        "            urls.extend(filtered_urls)\n",
        "\n",
        "        if urls and urls[0]:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(f\" [-] Downloading Custom {key}...\", color=\"flat_yellow\")\n",
        "\n",
        "        for url in urls:\n",
        "            url = url.strip()\n",
        "            if url != \"\":\n",
        "                print_line(80, color=\"green\")\n",
        "                if \"|\" in url:\n",
        "                    url, filename = map(str.strip, url.split(\"|\"))\n",
        "                    if not filename.endswith((\".safetensors\", \".ckpt\", \".pt\", \"pth\")):\n",
        "                        filename = filename + Path(get_filename(url)).suffix\n",
        "                else:\n",
        "                    filename = get_filename(url)\n",
        "\n",
        "                download(url=url, filename=filename, dst=dst, quiet=False)\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append(url)\n",
        "    return result_list\n",
        "\n",
        "def auto_select_file(target_dir, config_key, file_types):\n",
        "    if not os.path.exists(target_dir):\n",
        "        return None\n",
        "\n",
        "    valid_files = [f for f in os.listdir(target_dir) if f.endswith(file_types)]\n",
        "    if valid_files:\n",
        "        file_path = random.choice(valid_files)\n",
        "\n",
        "        if Path(target_dir).joinpath(file_path).exists():\n",
        "            config = config_utils.read_config(str(config_file_path))\n",
        "            config[config_key] = file_path\n",
        "            config_utils.write_config(str(config_file_path), config)\n",
        "        return file_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def ui_config_presets():\n",
        "    preset_prompt = \"masterpiece, best quality, very aesthetic, absurdres\"\n",
        "    preset_negative_prompt = \"nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\"\n",
        "\n",
        "    return {\n",
        "        \"txt2img/Prompt/value\"              : preset_prompt,\n",
        "        \"txt2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"img2img/Prompt/value\"              : preset_prompt,\n",
        "        \"img2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"customscript/sampler.py/txt2img/Sampling method/value\" : \"Euler a\",\n",
        "        \"customscript/sampler.py/txt2img/Sampling steps/value\"  : 28,\n",
        "        \"customscript/sampler.py/txt2img/Scheduler/value\"       : \"Automatic\",\n",
        "    }\n",
        "\n",
        "def ui_config_settings(ui_config_file: str):\n",
        "    config = config_utils.read_config(str(ui_config_file))\n",
        "    preset_config = ui_config_presets()\n",
        "\n",
        "    for key, value in preset_config.items():\n",
        "        config[key] = value\n",
        "\n",
        "    config_utils.write_config(str(ui_config_file), config)\n",
        "\n",
        "def general_config_presets(config_file: str, lora_dir: str, use_presets: bool, ui_config_file: str):\n",
        "    config = config_utils.read_config(str(config_file))\n",
        "\n",
        "    config.update({\n",
        "        \"CLIP_stop_at_last_layers\"      : 2,\n",
        "        \"show_progress_every_n_steps\"   : 10,\n",
        "        \"show_progressbar\"              : True,\n",
        "        \"samples_filename_pattern\"      : \"[model_name]_[seed]\",\n",
        "        \"show_progress_type\"            : \"Approx NN\",\n",
        "        \"live_preview_content\"          : \"Prompt\",\n",
        "        \"forge_preset\"                  : \"xl\",\n",
        "        \"xl_t2i_width\"                  : 832,\n",
        "        \"xl_t2i_height\"                 : 1216,\n",
        "        \"xl_t2i_cfg\"                    : 7,\n",
        "        \"xl_t2i_hr_cfg\"                 : 7,\n",
        "        \"xl_t2i_sampler\"                : \"Euler a\",\n",
        "        \"xl_t2i_scheduler\"              : \"Automatic\",\n",
        "        \"gradio_theme\"                  : gradio_theme,\n",
        "    })\n",
        "\n",
        "    config_utils.write_config(str(config_file), config)\n",
        "\n",
        "    if use_presets:\n",
        "        ui_config_settings(ui_config_file)\n",
        "\n",
        "def is_valid(target_dir, file_types):\n",
        "    if not os.path.exists(target_dir):\n",
        "        return False\n",
        "    return any(f.endswith(file_types) for f in os.listdir(target_dir))\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f'\"{v}\"')\n",
        "        elif isinstance(v, str):\n",
        "            args.append(f'--{k}=\"{v}\"')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, (float, int)) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "    return \" \".join(args)\n",
        "\n",
        "def main():\n",
        "    global output_dir, auto_select_model, auto_select_vae\n",
        "\n",
        "    ################################\n",
        "    # VERIFICAR PYTORCH PRIMERO\n",
        "    ################################\n",
        "    print_line(80, color=\"yellow\")\n",
        "    cprint(\"🔍 VERIFICANDO PYTORCH...\", color=\"yellow\")\n",
        "\n",
        "    verify_torch = sp.run([PYTHON, \"-c\", \"import torch; print(f'PyTorch: {torch.__version__}')\"],\n",
        "                          capture_output=True, text=True)\n",
        "    if verify_torch.returncode != 0:\n",
        "        cprint(\"❌ PyTorch NO está instalado en el venv\", color=\"red\")\n",
        "        cprint(\"Instalando PyTorch ahora...\", color=\"yellow\")\n",
        "        sp.run([PYTHON, \"-m\", \"pip\", \"install\", \"--no-cache-dir\",\n",
        "            \"torch\", \"torchvision\", \"torchaudio\",\n",
        "            \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
        "        ], check=True)\n",
        "        print_line(80, color=\"green\")\n",
        "    else:\n",
        "        cprint(f\"✅ {verify_torch.stdout.strip()}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    output_dir = mount_drive_function(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU: {gpu_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python {python_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch {torch_info}\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    try:\n",
        "        install_dependencies()\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        install_webui(repo_dir, cprint(\"Unpacking Web UI Forge\", color=\"green\", tqdm_desc=True))\n",
        "        prepare_environment()\n",
        "\n",
        "        configure_output_path(config_file_path, output_dir, output_subdir)\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        if update_webui and not commit_hash:\n",
        "            update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "        elif commit_hash:\n",
        "            reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "        setup_directories()\n",
        "\n",
        "        repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "        cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "        cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "        if update_extensions:\n",
        "            print_line(80, color=\"green\")\n",
        "            batch_update(fetch=True, directory=extensions_dir, desc=cprint(\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "        elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {str(e)}\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        cprint(\"Setup failed. Please check the error message above and try again.\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    custom_download(custom_dirs)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Launching '{repo_name}'\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if not is_valid(ckpt_dir, ('.ckpt', '.safetensors')):\n",
        "        cprint(f\"No checkpoints were found in the directory '{ckpt_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=ckpt_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_model = True\n",
        "\n",
        "    if not is_valid(vae_dir, ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt')):\n",
        "        cprint(f\"No VAEs were found in the directory '{vae_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl.vae.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=vae_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_vae = True\n",
        "\n",
        "    if auto_select_model:\n",
        "        selected_model  = auto_select_file(ckpt_dir, \"sd_model_checkpoint\", ('.ckpt', '.safetensors'))\n",
        "        cprint(f\"Selected Model: {selected_model}\", color=\"green\")\n",
        "\n",
        "    if auto_select_vae:\n",
        "        selected_vae    = auto_select_file(vae_dir, \"sd_vae\", ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt'))\n",
        "        cprint(f\"Selected VAE: {selected_vae}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    general_config_presets(config_file_path, lora_dir, use_presets, ui_config_file_path)\n",
        "\n",
        "    if use_gradio_auth:\n",
        "      cprint(\"Gradio Auth (use this account to login):\", color=\"green\")\n",
        "      cprint(\"[-] Username: cagliostro\", color=\"green\")\n",
        "      cprint(\"[-] Password:\", password, color=\"green\")\n",
        "      print_line(80, color=\"green\")\n",
        "\n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"gradio-auth\"                     : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                      : True,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"lowram\"                          : True,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"no-download-sd-model\"            : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : ckpt_dir,\n",
        "        \"vae-dir\"                         : vae_dir,\n",
        "        \"lora-dir\"                        : lora_dir,\n",
        "    }\n",
        "\n",
        "    args = parse_args(config)\n",
        "    final_args = f\"{PYTHON} launch.py {args} {additional_arguments}\"\n",
        "\n",
        "    cprint()\n",
        "    os.chdir(repo_dir)\n",
        "    subprocess.run(final_args, shell=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "YYzHDlgEkkrY",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "9a8c7778-5df6-4ada-8c8d-8bd7e8e7c05b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Actualizando sistema...\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,812 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,988 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,372 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,778 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 25.3 MB in 2s (13.7 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libffi-dev is already the newest version (3.4.2-4).\n",
            "libffi-dev set to manually installed.\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "libssl-dev is already the newest version (3.0.2-0ubuntu1.20).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-distutils set to manually installed.\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10 set to manually installed.\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2 python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 lz4 python3-pip-whl python3-setuptools-whl\n",
            "  python3.10-venv\n",
            "0 upgraded, 7 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 4,084 kB of archives.\n",
            "After this operation, 8,430 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 lz4 amd64 1.9.3-2build2 [90.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.7 [1,683 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools-whl all 68.1.2-2~jammy3 [792 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.11 [5,726 B]\n",
            "Fetched 4,084 kB in 1s (2,950 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../1-libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../2-aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package lz4.\n",
            "Preparing to unpack .../3-lz4_1.9.3-2build2_amd64.deb ...\n",
            "Unpacking lz4 (1.9.3-2build2) ...\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "Preparing to unpack .../4-python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../5-python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../6-python3.10-venv_3.10.12-1~22.04.11_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.11) ...\n",
            "Setting up python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up lz4 (1.9.3-2build2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.11) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "📥 Descargando get-pip.py...\n",
            "✅ Dependencias básicas instaladas\n",
            "🔨 Creando virtualenv Python 3.10...\n",
            "✅ Virtualenv creado en /content/venv310\n",
            "📦 Instalando pip, setuptools, wheel...\n",
            "⚙️  Configurando pip...\n",
            "✅ Pip, setuptools y wheel instalados\n",
            "🔥 Instalando PyTorch...\n",
            "✅ PyTorch instalado\n",
            "📦 Instalando dependencias de colablib...\n",
            "✅ Dependencias instaladas\n",
            "🚀 Instalando colablib...\n",
            "\n",
            "✅✅✅ ENTORNO COMPLETAMENTE CONFIGURADO ✅✅✅\n",
            "\n",
            "🔍 Python detectado en venv: Python 3.10.12\n",
            "\u001b[0m\u001b[0;33m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;33m🔍 VERIFICANDO PYTORCH...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m✅ PyTorch: 2.7.1+cu118\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nvidia-smi'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2046732104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2046732104.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmount_drive_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0mgpu_info\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gpu_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_gpu_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0mpython_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_python_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0mtorch_info\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_torch_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/venv310/lib/python3.10/site-packages/colablib/utils/py_utils.py\u001b[0m in \u001b[0;36mget_gpu_info\u001b[0;34m(get_gpu_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"nvidia-smi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--query-gpu=gpu_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--format=csv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nvidia-smi'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!NVIDIA-SMI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLvdJ7syPexA",
        "outputId": "b08bb25c-6e85-4e04-a741-28f01aa3045b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: NVIDIA-SMI: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"🔧 Solucionando warnings...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Instalar insightface para ControlNet\n",
        "print(\"\\n📦 Instalando insightface...\")\n",
        "subprocess.run([\n",
        "    \"/content/venv310/bin/pip\", \"install\",\n",
        "    \"insightface\",\n",
        "    \"--no-deps\",\n",
        "    \"-q\"\n",
        "], check=False)\n",
        "\n",
        "# 2. Verificar/crear directorios faltantes\n",
        "dirs_to_check = [\n",
        "    \"/content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\",\n",
        "    \"/content/stable-diffusion-webui-forge/extensions\"\n",
        "]\n",
        "\n",
        "print(\"\\n📁 Verificando directorios...\")\n",
        "for d in dirs_to_check:\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "        print(f\"   ✅ Creado: {d}\")\n",
        "    else:\n",
        "        print(f\"   ✓ Existe: {d}\")\n",
        "\n",
        "print(\"\\n✅ Warnings solucionados!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx7_e2O4a_Ve",
        "outputId": "3c5c8c08-f857-4d36-b16a-6cc39b6a592f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Solucionando warnings...\n",
            "================================================================================\n",
            "\n",
            "📦 Instalando insightface...\n",
            "\n",
            "📁 Verificando directorios...\n",
            "   ✓ Existe: /content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
            "   ✓ Existe: /content/stable-diffusion-webui-forge/extensions\n",
            "\n",
            "✅ Warnings solucionados!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "\n",
        "REPO_DIR = \"/content/stable-diffusion-webui-forge\"\n",
        "VENV_PYTHON = \"/content/venv310/bin/python\"\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(\"🚀 Configurando túnel Cloudflare para Forge...\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# Verificar si Forge ya está corriendo\n",
        "result = subprocess.run([\"ps\", \"aux\"], capture_output=True, text=True)\n",
        "forge_running = \"launch.py\" in result.stdout\n",
        "\n",
        "if not forge_running:\n",
        "    print(\"⚠️ Forge NO está corriendo. Iniciándolo...\\n\")\n",
        "\n",
        "    cmd = [\n",
        "        VENV_PYTHON, \"-u\", \"launch.py\",\n",
        "        \"--lowram\",\n",
        "        \"--listen\",\n",
        "        \"--theme\", \"dark\",\n",
        "        \"--no-half-vae\",\n",
        "        \"--opt-sdp-attention\",\n",
        "        \"--skip-python-version-check\"\n",
        "    ]\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env.pop('MPLBACKEND', None)\n",
        "    env['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        cmd,\n",
        "        env=env,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        universal_newlines=True\n",
        "    )\n",
        "\n",
        "    print(\"⏳ Esperando que Forge inicie...\\n\")\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < 35:\n",
        "        line = process.stdout.readline()\n",
        "        if line:\n",
        "            print(line, end='', flush=True)\n",
        "            if \"Running on local URL\" in line:\n",
        "                print(\"\\n✅ Forge iniciado!\\n\")\n",
        "                break\n",
        "\n",
        "    time.sleep(5)\n",
        "else:\n",
        "    print(\"✅ Forge ya está corriendo\\n\")\n",
        "\n",
        "# Crear túnel Cloudflare\n",
        "print(\"=\"*80)\n",
        "print(\"🌐 Creando túnel público con Cloudflare...\")\n",
        "print(\"⏳ Esto puede tardar 10-15 segundos...\\n\")\n",
        "\n",
        "cf_process = subprocess.Popen(\n",
        "    [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:7860\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    universal_newlines=True\n",
        ")\n",
        "\n",
        "# Buscar la URL en la salida\n",
        "url_found = False\n",
        "for _ in range(30):\n",
        "    line = cf_process.stdout.readline()\n",
        "    if line:\n",
        "        # Buscar URLs en el formato trycloudflare.com\n",
        "        match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
        "        if match:\n",
        "            url = match.group(0)\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"✅ ¡TODO LISTO! Accede a Forge aquí:\")\n",
        "            print(f\"\\n🔗 {url}\")\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"💡 SIN CONTRASEÑA - Acceso directo\")\n",
        "            print(\"💡 Esta URL es pública y estable\")\n",
        "            print(\"=\"*80)\n",
        "            url_found = True\n",
        "            break\n",
        "    time.sleep(0.5)\n",
        "\n",
        "if not url_found:\n",
        "    print(\"⚠️ No se pudo obtener la URL automáticamente\")\n",
        "    print(\"Revisa la salida arriba manualmente para encontrarla\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1RIO71fP0Kb",
        "outputId": "7628727d-a4de-44e8-ad1d-e41bcd6eae84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 126783 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.10.0) ...\n",
            "Setting up cloudflared (2025.10.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "🚀 Configurando túnel Cloudflare para Forge...\n",
            "================================================================================\n",
            "\n",
            "✅ Forge ya está corriendo\n",
            "\n",
            "================================================================================\n",
            "🌐 Creando túnel público con Cloudflare...\n",
            "⏳ Esto puede tardar 10-15 segundos...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "✅ ¡TODO LISTO! Accede a Forge aquí:\n",
            "\n",
            "🔗 https://collaborative-breakdown-represents-breakfast.trycloudflare.com\n",
            "\n",
            "================================================================================\n",
            "💡 SIN CONTRASEÑA - Acceso directo\n",
            "💡 Esta URL es pública y estable\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar ngrok correctamente\n",
        "print(\"📦 Instalando pyngrok...\")\n",
        "import subprocess\n",
        "result = subprocess.run(\n",
        "    [\"pip\", \"install\", \"pyngrok\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "print(result.stdout)\n",
        "if result.returncode == 0:\n",
        "    print(\"✅ pyngrok instalado correctamente\")\n",
        "else:\n",
        "    print(\"❌ Error:\", result.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCjedXotdF84",
        "outputId": "d2a368d4-db6a-4865-a69d-cc01d143d7ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Instalando pyngrok...\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.3)\n",
            "\n",
            "✅ pyngrok instalado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"🔍 Verificando procesos de Forge...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "result = subprocess.run(\n",
        "    [\"ps\", \"aux\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "forge_processes = [line for line in result.stdout.split('\\n') if 'launch.py' in line]\n",
        "\n",
        "if forge_processes:\n",
        "    print(\"✅ Forge está corriendo:\")\n",
        "    for proc in forge_processes:\n",
        "        print(f\"   {proc}\")\n",
        "else:\n",
        "    print(\"❌ Forge NO está corriendo (el proceso murió)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"\\n🔍 Intentando conectar al puerto 7860...\")\n",
        "\n",
        "import socket\n",
        "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "result = sock.connect_ex(('127.0.0.1', 7860))\n",
        "sock.close()\n",
        "\n",
        "if result == 0:\n",
        "    print(\"✅ El puerto 7860 está abierto y escuchando\")\n",
        "else:\n",
        "    print(\"❌ El puerto 7860 NO está disponible\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlKOrG1RcbqL",
        "outputId": "273fbdda-a2a2-41d3-aeb2-56885e929550"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Verificando procesos de Forge...\n",
            "================================================================================\n",
            "✅ Forge está corriendo:\n",
            "   root       43829 18.1  7.5 9824248 1004904 ?     Sl   22:24   0:19 /content/venv310/bin/python -u launch.py --lowram --listen --theme dark --no-half-vae --opt-sdp-attention --skip-python-version-check\n",
            "\n",
            "================================================================================\n",
            "\n",
            "🔍 Intentando conectar al puerto 7860...\n",
            "✅ El puerto 7860 está abierto y escuchando\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from colablib.colored_print import cprint\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "use_drive = False  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-forge-colab\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "def get_unique_filename(base_filename):\n",
        "    path = Path(base_filename)\n",
        "    if not path.exists():\n",
        "        return path\n",
        "    i = 1\n",
        "    while True:\n",
        "        new_path = path.with_name(f\"{path.stem}({i}){path.suffix}\")\n",
        "        if not new_path.exists():\n",
        "            return new_path\n",
        "        i += 1\n",
        "\n",
        "filename = get_unique_filename(filename)\n",
        "\n",
        "def zip_directory(directory, zipname):\n",
        "    with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in directory.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                zipf.write(file_path, file_path.relative_to(directory.parent))\n",
        "\n",
        "zip_directory(output_dir, Path('/content/outputs.zip'))\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive_service = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        query = f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        file_list = drive_service.ListFile({\"q\": query}).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: Folder exists\", color=\"green\")\n",
        "            return file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(\"Debug: Creating folder\", color=\"green\")\n",
        "            folder = drive_service.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            folder.Upload()\n",
        "            return folder[\"id\"]\n",
        "\n",
        "    def upload_file(file_path, folder_id, save_as):\n",
        "        save_as = get_unique_filename(save_as)\n",
        "        file = drive_service.CreateFile({\"title\": save_as.name, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(str(file_path))\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file[\"id\"]\n",
        "\n",
        "    folder_id = create_folder(folder_name)\n",
        "    file_id = upload_file(Path('/content/outputs.zip'), folder_id, Path(save_as))\n",
        "    sharing_link = f\"https://drive.google.com/file/d/{file_id}/view?usp=sharing\"\n",
        "    cprint(f\"Your sharing link: {sharing_link}\", color=\"green\")\n",
        "else:\n",
        "    cprint(\"Files zipped locally. Download manually from the files tab.\", color=\"yellow\")\n"
      ],
      "metadata": {
        "id": "UyTKsCa1qUL4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}